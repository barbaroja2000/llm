{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMPOuLZw3Kr24NkLUNuQPRp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barbaroja2000/llm/blob/main/Langchain_OpenAi_QA_%26_Summarize_Webpages%7CYoutube%7Cpdfs%7Ctxt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Langchain OpenAi - QA & Summarize Webpages|Youtube|pdfs|txt.ipynb\n",
        "\n",
        "This colab provides a utility with the following functionality\n",
        "\n",
        "* Summarize Text\n",
        "* Q&A on text\n",
        "\n",
        "Text can be loaded from:\n",
        "\n",
        "* Uploaded .pdf\n",
        "* Transcribed youtube video \n",
        "* Web Page\n",
        "\n",
        "Uses langchain, FAISS (Vector Store), OpenAi & PromptTemplates\n",
        "\n",
        "https://python.langchain.com/en/latest/index.html\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/prompts/prompt_templates.html\n",
        "\n",
        "To run you will need an OpenAi API Key, as an environment variable:\n",
        "\n",
        "```\n",
        "import os\n",
        "os.environ.get(\"OPENAI_API_KEY\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "F0tLNCtO6kBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Keys\n",
        "#@markdown Utitily to load keys from fs, replace with environ vars if not using\n",
        "\n",
        "import os\n",
        "\n",
        "#os.environ.get(\"OPENAI_API_KEY\")\n",
        "#os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
        "\n",
        "!python -m pip install python-dotenv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "import dotenv\n",
        "dotenv.load_dotenv('/content/drive/MyDrive/keys/keys.env')"
      ],
      "metadata": {
        "id": "8xIXPCQ-6H8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain openai pypdf tiktoken faiss-cpu unstructured youtube_transcript_api beautifulsoup4 > /dev/null"
      ],
      "metadata": {
        "id": "wmSnChLV45bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate, LLMChain, OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import TextFormatter\n",
        "import os , requests\n",
        "from typing import List, Dict\n",
        "import glob\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "GOm2g30q_1Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Download .pdf\n",
        "#!wget https://d1.awsstatic.com/whitepapers/building-a-cloud-operating-model.pdf\n",
        "#!wget https://d1.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf\n",
        "!wget https://docs.aws.amazon.com/pdfs/wellarchitected/latest/sustainability-pillar/wellarchitected-sustainability-pillar.pdf"
      ],
      "metadata": {
        "id": "6CL4PUC5Zuae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  SummarizeNQA Class \n",
        "\n",
        "class SummarizeNQA:\n",
        "    def __init__(self, key: str, dir: str) -> None:\n",
        "        if not key:\n",
        "            raise ValueError(\"API key must be provided.\")\n",
        "        if not dir  or not os.path.isdir(dir):\n",
        "            raise ValueError(\"Directory must be provided.\")      \n",
        "        self.key = key\n",
        "        self.dir = dir\n",
        "        self.db = None\n",
        "        self.docs = None\n",
        "\n",
        "    @staticmethod\n",
        "    def request(url:str) -> None:\n",
        "        page = requests.get(url)\n",
        "        if not page.status_code == 200:\n",
        "          raise ValueError(\"Must pass valid url\")\n",
        "\n",
        "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "        [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
        "        text_formatted = soup.getText()\n",
        "\n",
        "        file_name = url.split(\"/\")[-1]\n",
        "        with open(f'{file_name}.txt', 'w') as f:\n",
        "            f.write(text_formatted)\n",
        "            \n",
        "    @staticmethod\n",
        "    def _check_video_url(video_id: str):\n",
        "      checker_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "      request = requests.get(checker_url)\n",
        "      return request.status_code == 200\n",
        "\n",
        "    def youtube(self, id: str) -> None:\n",
        "\n",
        "      if not id or not self._check_video_url(id):\n",
        "        raise ValueError(\"Must pass valid youtube ID\")\n",
        "\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(id)\n",
        "      formatter = TextFormatter()\n",
        "      text_formatted = formatter.format_transcript(transcript)\n",
        "      with open(f'{id}.txt', 'w') as f:\n",
        "        f.write(text_formatted)\n",
        "\n",
        "    def load(self, chunk_size: int = 2000, chunk_overlap: int = 200) -> None:\n",
        "        \n",
        "        documents = []\n",
        "        if not glob.glob(f\"{self.dir}*.*\"):\n",
        "            raise ValueError(\"Directory must contain at least one file.\")\n",
        "\n",
        "        if  glob.glob(f\"{self.dir}*.pdf\"):\n",
        "          loader = DirectoryLoader(\n",
        "              \"\", glob=f\"{self.dir}*.pdf\", loader_cls=PyPDFLoader\n",
        "          )\n",
        "          documents = [*loader.load(), *documents]\n",
        "\n",
        "        if  glob.glob(f\"{self.dir}*.txt\"):\n",
        "          loader = DirectoryLoader(\n",
        "              \"\", glob=f\"{self.dir}*.txt\", loader_cls=TextLoader\n",
        "          )\n",
        "          documents = [*loader.load(), *documents]\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        self.docs  = text_splitter.split_documents(documents)\n",
        "        embeddings = OpenAIEmbeddings(openai_api_key=self.key)\n",
        "        self.db = FAISS.from_documents(self.docs, embeddings)\n",
        "    \n",
        "    def summarize(self, max_tokens=1000,chain_type='map_reduce' ):\n",
        "\n",
        "      if not self.db:\n",
        "         raise ValueError(\"Load first\")\n",
        "\n",
        "      map_prompt = \"\"\"\n",
        "                Write a  summary of the following:\n",
        "                \"{text}\"\n",
        "                 SUMMARY:\n",
        "                \"\"\"\n",
        "      map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
        "\n",
        "      combine_prompt = \"\"\"\n",
        "      Write a  summary of the following text delimited by triple backquotes.\n",
        "      Return your response in bullet points which covers the key points of the text.\n",
        "      ```{text}```\n",
        "      BULLET POINT  SUMMARY:\n",
        "      \"\"\"\n",
        "      combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])\n",
        "\n",
        "      llm = OpenAI(temperature=0, openai_api_key=self.key,  max_tokens=max_tokens)\n",
        "\n",
        "      summary_chain = load_summarize_chain(llm=llm,\n",
        "              chain_type=chain_type,\n",
        "              map_prompt=map_prompt_template,\n",
        "              combine_prompt=combine_prompt_template,\n",
        "              verbose=False, return_intermediate_steps=False\n",
        "          )\n",
        "\n",
        "      return  summary_chain.run(self.docs)\n",
        "\n",
        "    def qa(\n",
        "        self,\n",
        "        query: str,\n",
        "        temperature: float = 0,\n",
        "        count: float = 4,\n",
        "        chain_type: str = \"stuff\", #map_reduce, #refine\n",
        "        return_only_outputs: bool = True,\n",
        "        return_intermediate_steps: bool = False,\n",
        "    ) -> Dict:\n",
        "\n",
        "        docs = self.db.similarity_search(query, k=count)\n",
        "\n",
        "        if chain_type == \"stuff\":\n",
        "            chain = load_qa_with_sources_chain(OpenAI(temperature=temperature, openai_api_key=self.key), chain_type=chain_type)\n",
        "        else:\n",
        "            load_qa_with_sources_chain(OpenAI(temperature=temperature, openai_api_key=self.key), chain_type=chain_type, return_intermediate_steps=return_intermediate_steps)\n",
        "        return chain(\n",
        "            {\"input_documents\": docs, \"question\": query},\n",
        "            return_only_outputs=return_only_outputs,\n",
        "        )"
      ],
      "metadata": {
        "id": "2Z2rBLYM6iVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Set Up\n",
        "summarize_and_qa = SummarizeNQA(os.environ.get(\"OPENAI_API_KEY\"),\"./\")"
      ],
      "metadata": {
        "id": "pWJzOLG85qXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transcribe a youtube video\n",
        "#https://www.youtube.com/watch?v=PdE-waSx-d8\n",
        "summarize_and_qa.youtube(\"PdE-waSx-d8\")"
      ],
      "metadata": {
        "id": "5lCNaIvXuR_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load text from a url\n",
        "summarize_and_qa.request(\"https://energysavingtrust.org.uk/case-study/green-energy\")"
      ],
      "metadata": {
        "id": "BbheyXVxzIVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the texts into documents and index\n",
        "summarize_and_qa.load()"
      ],
      "metadata": {
        "id": "Cqet_uwtQr66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Summarize\n",
        "# @markdown ```Depending on the length of the text, you may have to reduce the max_token parameter```\n",
        "summary = summarize_and_qa.summarize(max_tokens=1000)\n",
        "summary"
      ],
      "metadata": {
        "id": "_EMuokDq1vn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "metadata": {
        "id": "2EiGXICOB5_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title QA\n",
        "response = summarize_and_qa.qa(\"Explain the ideas in computational irreducibility\")\n",
        "response[\"output_text\"]"
      ],
      "metadata": {
        "id": "VMt4NJ818aOB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}