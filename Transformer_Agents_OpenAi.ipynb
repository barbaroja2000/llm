{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barbaroja2000/llm/blob/main/Transformer_Agents_OpenAi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer Agents with OpenAI\n",
        "\n",
        "This colab explores the functionality in Transformer agents\n",
        "\n",
        "* Image Generation & Modification\n",
        "*  Audio production & transcription\n",
        "* Video generation\n",
        "* Chat Mode\n",
        "* Custom Tools\n",
        "\n",
        "To run you will need an OpenAi API Key and HuggingFace API key, as environment variables:\n",
        "\n",
        "```\n",
        "OPENAI_API_KEY=\"\"\n",
        "HUGGINGFACE_API_KEY=\"\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xbR6LTWpEM4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Image](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/diagram.png)\n",
        "\n",
        "**Built in tools:**\n",
        "\n",
        "* Document question answering: given a document (such as a PDF) in image format, answer a question on this document (Donut)\n",
        "* Text question answering: given a long text and a question, answer the question in the text (Flan-T5)\n",
        "* Unconditional image captioning: Caption the image! (BLIP)\n",
        "* Image question answering: given an image, answer a question on this image (VILT)\n",
        "* Image segmentation: given an image and a prompt, output the segmentation mask of that prompt (CLIPSeg)\n",
        "* Speech to text: given an audio recording of a person talking, transcribe the speech into text (Whisper)\n",
        "* Text to speech: convert text to speech (SpeechT5)\n",
        "* Zero-shot text classification: given a text and a list of labels, identify to which label the text corresponds the most (BART)\n",
        "* Text summarization: summarize a long text in one or a few sentences (BART)\n",
        "* Translation: translate the text into a given language (NLLB)\n",
        "* Transformers Agent Custom Tools.\n",
        "\n",
        "**Custom Tools:**\n",
        "\n",
        "* Text downloader: to download a text from a web URL\n",
        "* Text to image: generate an image according to a prompt, leveraging stable diffusion\n",
        "* Image transformation: modify an image given an initial image and a prompt, leveraging instruct pix2pix stable diffusion\n",
        "* Text to video: generate a small video according to a prompt, leveraging damo-vilab\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "https://huggingface.co/docs/transformers/en/transformers_agents\n",
        "\n",
        "https://colab.research.google.com/drive/1c7MHD-T1forUPGcC_jlwsIptOzpG3hSj\n"
      ],
      "metadata": {
        "id": "WmiBb_xt8elx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Keys\n",
        "!python -m pip install python-dotenv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "import dotenv\n",
        "import os\n",
        "dotenv.load_dotenv('/content/drive/MyDrive/keys/keys.env')\n"
      ],
      "metadata": {
        "id": "5r0azyveVGKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4SPw04cT9Y1"
      },
      "outputs": [],
      "source": [
        "#@title Installation\n",
        "transformers_version = \"v4.29.2\" #@param [\"main\", \"v4.29.2\"] {allow-input: true}\n",
        "!pip install huggingface_hub>=0.14.1 git+https://github.com/huggingface/transformers@$transformers_version -q diffusers accelerate datasets torch soundfile sentencepiece opencv-python openai transformers\n",
        "!pip install youtube_transcript_api beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sound\n",
        "import IPython\n",
        "import soundfile as sf\n",
        "\n",
        "def play_audio(audio):\n",
        "    sf.write(\"speech_converted.wav\", audio.numpy(), samplerate=16000)\n",
        "    return IPython.display.Audio(\"speech_converted.wav\")"
      ],
      "metadata": {
        "id": "8ekYJDGc-u4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nEHtKNja52V"
      },
      "source": [
        "# OpenAi Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA8jPddeUSMO"
      },
      "outputs": [],
      "source": [
        "from transformers.tools import OpenAiAgent\n",
        "agent = OpenAiAgent(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpmYouC4_yzP"
      },
      "source": [
        "## Using the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJfEhaNTU_nZ"
      },
      "outputs": [],
      "source": [
        "#Examples : \"Generate an image of two cheshire cats, one black, one tabby staring at the camera\"\n",
        "picture_seed =  'Generate a picture of two godzillas fighting. photorealistic. both godzillas should side on and fully visible in the frame' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "picture = agent.run(picture_seed)\n",
        "picture"
      ],
      "metadata": {
        "id": "4nBnmIP7FV9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples : \"Generate an image of two cheshire cats, one black, one tabby staring at the camera\"\n",
        "picture_seed2 =  'the godzillas should be replaced with lego versions' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "4THkrPtVHjNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "picture_replaced = agent.run(picture_seed2, image=picture)\n",
        "picture_replaced"
      ],
      "metadata": {
        "id": "fqEMiuDLwQDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Audio Produce & Transcribe"
      ],
      "metadata": {
        "id": "jJzOED8hRNUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvgWWrVKt24u"
      },
      "outputs": [],
      "source": [
        "audio = agent.run(\"Read out loud the summary of https://en.wikipedia.org/wiki/Chuck_Norris\")\n",
        "play_audio(audio)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Provide transcript of this audio\", audio=audio)"
      ],
      "metadata": {
        "id": "TiVmfJQsQ69W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video\n",
        "Requires high Memory, borks on standard Colab."
      ],
      "metadata": {
        "id": "cRovQXlmTpFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples : \"Generate an image of two cheshire cats, one black, one tabby staring at the camera\"\n",
        "video_seed =  'Generate a video of  Darth Vader  dancing' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "S4QYinA1Sr6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video = agent.run(video_seed)"
      ],
      "metadata": {
        "id": "FbtNFQfqSvJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def produce_video(frames):\n",
        "  result = [(r).astype(\"uint8\") for r in frames]\n",
        "  imageio.mimsave(\"video.mp4\", result, fps=5)\n",
        "  mp4 = open('/content/video.mp4','rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  video_html = f\"\"\"\n",
        "    <video width=400 controls>\n",
        "          <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "  \"\"\"\n",
        "  return video_html"
      ],
      "metadata": {
        "id": "3jiCX-VSxbVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_html = produce_video(video)\n",
        "HTML(video_html)"
      ],
      "metadata": {
        "id": "odV2qyWQuTb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKPC_atPK-JB"
      },
      "source": [
        "### Chat mode\n",
        "- `.run` does not keep memory across runs, but performs better for multiple operations at once (such as running two, or three tools in a row from a given instruction)\n",
        "- `.chat` keeps memory across runs, but performs better at single instructions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples : \"Generate an image of two cheshire cats, one black, one tabby staring at the camera\"\n",
        "picture_seed3 =  'Create an photorealistic image of  an Oompa Lumpa' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "tvl9zr8nNUCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wns48i10ZdR2"
      },
      "outputs": [],
      "source": [
        "agent.chat(picture_seed3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples : \"Generate an image of two cheshire cats, one black, one tabby staring at the camera\"\n",
        "picture_seed4 =  'Change this image so the Oompa Loompa looks like a leprechaun' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "G5DpGEUlNnvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHeEmhWxN922"
      },
      "outputs": [],
      "source": [
        "agent.chat(picture_seed4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom Tools\n",
        "\n",
        "Example below takes a youtube id and creates transcript from it"
      ],
      "metadata": {
        "id": "7n0_bmmQDIf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import Tool\n",
        "import requests\n",
        "from huggingface_hub import list_models\n",
        "from youtube_transcript_api.formatters import TextFormatter\n",
        "\n",
        "class YouTubeTranscriptFetcher(Tool):\n",
        "    name = \"youtube_transcript_fetcher\"\n",
        "    description = (\"This is a tool that fetches a transcript of a youtube video. It takes input of video id, and returns the transcript of the video.\")\n",
        "\n",
        "    inputs = [\"text\"]\n",
        "    outputs = [\"text\"]\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_video_url(video_id: str):\n",
        "      checker_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "      request = requests.get(checker_url)\n",
        "      return request.status_code == 200\n",
        "\n",
        "    def __call__(self, video_id:str):\n",
        "      print(video_id)\n",
        "\n",
        "      if not video_id or not self._check_video_url(video_id):\n",
        "        raise ValueError(\"Must pass valid youtube ID\")\n",
        "\n",
        "      transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "      formatter = TextFormatter()\n",
        "      text_formatted = formatter.format_transcript(transcript)\n",
        "      return text_formatted\n",
        "\n"
      ],
      "metadata": {
        "id": "vPwm0ADdhtj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A conversation with OpenAI CEO Sam Altman\n",
        "tool = YouTubeTranscriptFetcher()\n",
        "tool(\"uRIWgbvouEw\")"
      ],
      "metadata": {
        "id": "mT9dGNK7l-v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2FbsfD2HtU8"
      },
      "outputs": [],
      "source": [
        "from transformers.tools import HfAgent\n",
        "from transformers import OpenAiAgent\n",
        "\n",
        "agent = OpenAiAgent(model=\"gpt-4\", additional_tools=[tool])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6dWvZvtKFBT"
      },
      "outputs": [],
      "source": [
        "agent.run(\"Fetch the youtube transcript of uRIWgbvouEw and summarize\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}