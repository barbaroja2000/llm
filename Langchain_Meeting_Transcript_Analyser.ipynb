{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9j3vbDjUkJWCyi5UB3LGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barbaroja2000/llm/blob/main/Langchain_Meeting_Transcript_Analyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Langchain Meeting Transcript Analyser\n",
        "\n",
        "This colab provides a test harness to experiment with prompt engineering required to extract the following information from a .vtt file.\n",
        "\n",
        "Participants\n",
        "\n",
        "*   Meeting topic (metadata or parsed)\n",
        "*   Meeting date, time, location (metadata or parsed)\n",
        "*   Meeting actions & deadlines\n",
        "*   Meeting key points\n",
        "*   Decisions Made\n",
        "*   Questions: Raised (and possibly unanswered)\n",
        "\n",
        "Notes:\n",
        "\n",
        "* Embedding model -  \"sentence-transformers/all-mpnet-base-v2\"\n",
        "* FAISS for Vector store - swap out with pinecone\n",
        "* Model meta-llama/Llama-2-70b-chat-hf\n",
        "* Chunk size for documents 1000 char with 100 overlap\n",
        "* 512 max new tokens Llama-2-70b-chat-hf\n"
      ],
      "metadata": {
        "id": "F0tLNCtO6kBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Keys\n",
        "#@markdown Utitily to load keys from fs, replace with environ vars if not using\n",
        "\n",
        "import os\n",
        "\n",
        "#os.environ.get(\"OPENAI_API_KEY\")\n",
        "#os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "!python -m pip install python-dotenv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "import dotenv\n",
        "dotenv.load_dotenv('/content/drive/MyDrive/keys/keys.env')"
      ],
      "metadata": {
        "id": "8xIXPCQ-6H8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4cd62b-8190-46e5-d309-6104f13fcd12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn on wandb logging for langchain\n",
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
      ],
      "metadata": {
        "id": "03M86hyNls_i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Synthetic .vtt meeting transcript\n",
        "synthetic_transcript_uri=\"https://gist.githubusercontent.com/barbaroja2000/277fd35e17ae6bc8610c29591f39c3a9/raw/5ecd4dc010e98c54f2d1537835a6acff4317443a/synthetic-transcript\""
      ],
      "metadata": {
        "id": "PplGx_PqAdgK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def fetch_text_file(url, save_path):\n",
        "    \"\"\"\n",
        "    Fetch a text file from a URL and save it locally.\n",
        "\n",
        "    Parameters:\n",
        "    - url (str): The URL of the text file.\n",
        "    - save_path (str): Local path where the file should be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Ensure the request was successful\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Write the content to a local file\n",
        "    with open(save_path, 'w', encoding=response.encoding) as file:\n",
        "        file.write(response.text)\n",
        "\n",
        "\n",
        "save_path = 'synthetic_transcript.vtt'\n",
        "fetch_text_file(synthetic_transcript_uri, save_path)"
      ],
      "metadata": {
        "id": "lzAhnCaHAlAm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain faiss-cpu huggingface_hub sentence_transformers wandb > /dev/null"
      ],
      "metadata": {
        "id": "wmSnChLV45bO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import PromptTemplate, LLMChain, HuggingFaceHub\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "import os , requests\n",
        "from typing import List, Dict\n",
        "import glob\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "GOm2g30q_1Dq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
      ],
      "metadata": {
        "id": "hGDDmwnhB34A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  SummarizeNQA Class\n",
        "\n",
        "class SummarizeNQA:\n",
        "    def __init__(self, key: str, dir: str) -> None:\n",
        "        if not key:\n",
        "            raise ValueError(\"API key must be provided.\")\n",
        "        if not dir  or not os.path.isdir(dir):\n",
        "            raise ValueError(\"Directory must be provided.\")\n",
        "\n",
        "        self.key = key\n",
        "        self.dir = dir\n",
        "        self.db = None\n",
        "        self.docs = None\n",
        "\n",
        "    def load(self, chunk_size: int = 1000, chunk_overlap: int = 100) -> None:\n",
        "\n",
        "        documents = []\n",
        "        if not glob.glob(f\"{self.dir}*.*\"):\n",
        "            raise ValueError(\"Directory must contain at least one file.\")\n",
        "\n",
        "        if  glob.glob(f\"{self.dir}*.vtt\"):\n",
        "          loader = DirectoryLoader(\n",
        "              \"\", glob=f\"{self.dir}*.vtt\", loader_cls=TextLoader\n",
        "          )\n",
        "          documents = [*loader.load(), *documents]\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        self.docs  = text_splitter.split_documents(documents)\n",
        "\n",
        "        embeddings = HuggingFaceEmbeddings( model_name=\"sentence-transformers/all-mpnet-base-v2\") #what other ones to use here\n",
        "        self.db = FAISS.from_documents(self.docs, embeddings)\n",
        "\n",
        "    def summarize(self, max_tokens=1000,chain_type='map_reduce' ):\n",
        "\n",
        "      if not self.db:\n",
        "         raise ValueError(\"Load first\")\n",
        "\n",
        "      map_prompt = \"\"\"\n",
        "                Write a  summary of the following:\n",
        "                \"{text}\"\n",
        "                 SUMMARY:\n",
        "                \"\"\"\n",
        "      map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
        "\n",
        "      combine_prompt = \"\"\"\n",
        "      Write a  summary of the following text delimited by triple backquotes.\n",
        "      Return your response in bullet points which covers the key points of the text.\n",
        "      ```{text}```\n",
        "      BULLET POINT  SUMMARY:\n",
        "      \"\"\"\n",
        "      combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])\n",
        "\n",
        "      repo_id = \"meta-llama/Llama-2-70b-chat-hf\"\n",
        "\n",
        "      llm = HuggingFaceHub(\n",
        "          huggingfacehub_api_token=self.key,\n",
        "          repo_id=repo_id, model_kwargs={\"max_new_tokens\":512}\n",
        "      )\n",
        "\n",
        "      summary_chain = load_summarize_chain(llm=llm,\n",
        "              chain_type=chain_type,\n",
        "              map_prompt=map_prompt_template,\n",
        "              combine_prompt=combine_prompt_template,\n",
        "              verbose=False, return_intermediate_steps=False\n",
        "          )\n",
        "\n",
        "      return  summary_chain.run(self.docs)\n",
        "\n",
        "    def qa(\n",
        "        self,\n",
        "        query: str,\n",
        "        temperature: float = 0,\n",
        "        count: float = 4,\n",
        "        chain_type: str = \"stuff\", #map_reduce, #refine\n",
        "        return_only_outputs: bool = True,\n",
        "        return_intermediate_steps: bool = False,\n",
        "    ) -> Dict:\n",
        "\n",
        "        docs = self.db.similarity_search(query, k=count)\n",
        "\n",
        "        repo_id = \"meta-llama/Llama-2-70b-chat-hf\"\n",
        "\n",
        "        llm = HuggingFaceHub(\n",
        "              huggingfacehub_api_token=self.key,\n",
        "              repo_id=repo_id, model_kwargs={\"max_new_tokens\":512}\n",
        "          )\n",
        "\n",
        "        if chain_type == \"stuff\":\n",
        "            chain = load_qa_with_sources_chain(llm, chain_type=chain_type)\n",
        "        else:\n",
        "            chain =  load_qa_with_sources_chain(llm, chain_type=chain_type, return_intermediate_steps=return_intermediate_steps)\n",
        "        return chain(\n",
        "            {\"input_documents\": docs, \"question\": query},\n",
        "            return_only_outputs=return_only_outputs,\n",
        "        )"
      ],
      "metadata": {
        "id": "2Z2rBLYM6iVA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Set Up\n",
        "summarize_and_qa = SummarizeNQA(os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\"),\"./\")"
      ],
      "metadata": {
        "id": "pWJzOLG85qXj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the texts into documents and index\n",
        "summarize_and_qa.load()"
      ],
      "metadata": {
        "id": "Cqet_uwtQr66"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Summarize\n",
        "# @markdown ```Depending on the length of the text, you may have to reduce the max_token parameter```\n",
        "import re\n",
        "summary = summarize_and_qa.summarize(max_tokens=1000)\n",
        "summary = re.sub('\\n{3,}', '\\n\\n', summary) #summary generates a lot of \\n characters"
      ],
      "metadata": {
        "id": "_EMuokDq1vn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "6cf89bb9-682e-4ec1-ff92-1324be84d189"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LangChain activity to W&B at https://wandb.ai/bandulu/uncategorized/runs/wa5mx1yz\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbTracer` is currently in beta.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3941 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3941 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2382 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "metadata": {
        "id": "2EiGXICOB5_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64a3523-4ce6-4acf-e049-a26deb58a035"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      * IT director calls a meeting to discuss a new AI strategy for clients.\n",
            "      * Head of architecture mentions an increase in client interest in AI, particularly generative AI.\n",
            "      * Principal architect highlights the potential of generative AI in content creation, design, and simulation.\n",
            "      * Managing director emphasizes the importance of developing universal AI products for clients.\n",
            "      * Company discusses AI capabilities and how to make them stand out in the market.\n",
            "      * Enterprise architect highlights predictive analytics and automation in finance and healthcare.\n",
            "      * Head of marketing stresses the importance of differentiation.\n",
            "      * IT director suggests partnering with industry leaders to gain an edge.\n",
            "      * Principal architect emphasizes the need for a robust technical infrastructure to support resource-intensive AI operations.\n",
            "      * AC Head of Architecture suggests dedicated GPU clusters and collaborations with cloud providers.\n",
            "      * BD Managing Director tasks AJ Principal Architect with leading a team to evaluate infrastructure needs and scout for potential partnerships.\n",
            "      * MM Enterprise Architect emphasizes the importance of security as a foundational component of AI products.\n",
            "      * GC IT Director suggests dedicating a team to ensure compliance with data protection regulations.\n",
            "      * Head of marketing suggests hosting a workshop to demonstrate AI capabilities to clients and generate interest in sales.\n",
            "      * Head of architecture agrees and suggests showcasing case studies and real-world applications, emphasizing customization and client-specific benefits.\n",
            "      * Managing director tasks head of marketing with coordinating the workshop and gathering client feedback.\n",
            "      * Principal architect adds that training for the team is also essential to keep up-to-date with the latest AI advancements.\n",
            "      * Discussion turns to the importance of continuous learning and collaboration with universities for AI research.\n",
            "      * MM suggests collaborating with universities for both training and academic insights.\n",
            "      * BD and AC agree, highlighting the potential for recruiting fresh talent and gaining access to research that can be commercialized.\n",
            "      * AJ suggests setting aside a budget for internal R&D to ensure constant innovation.\n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "      \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Meeting Participants\n",
        "response = summarize_and_qa.qa(\"list the meeting participants\",chain_type=\"map_reduce\")\n",
        "print(response[\"output_text\"])"
      ],
      "metadata": {
        "id": "VMt4NJ818aOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d30fda-a64e-4a74-a4d3-6c4a9ebeed7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meeting participants are:\n",
            "\n",
            "1. AC Head of Architecture\n",
            "2. BD Managing Director\n",
            "3. AJ Principal Architect\n",
            "4. MM Enterprise Architect\n",
            "5. GC IT Director\n",
            "6. RM Head of Marketing\n",
            "\n",
            "SOURCES:\n",
            "\n",
            "1. synthetic_transcript.vtt\n",
            "2. synthetic_transcript.vtt\n",
            "3. synthetic_transcript.vtt\n",
            "4. synthetic_transcript.vtt\n",
            "5. synthetic_transcript.vtt\n",
            "6. synthetic_transcript.vtt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Actions and Deadlines\n",
        "response = summarize_and_qa.qa(\"describe the meeting follow-on actions and any deadlines\",chain_type=\"map_reduce\")\n",
        "print(response[\"output_text\"])"
      ],
      "metadata": {
        "id": "UAJ0eU1G4XRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830245db-5461-4716-a358-2d1ac34c1b33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meeting follow-on actions and deadlines are as follows:\n",
            "\n",
            "1. Coordinate with sales team to arrange a workshop for clients (no deadline specified).\n",
            "2. Draft a proposal for the team structure and responsibilities (no deadline specified).\n",
            "3. Evaluate infrastructure needs for scalable AI and prepare a report (deadline: three weeks from the date of the meeting).\n",
            "4. Collaborate with universities for training and academic insights (no deadline specified).\n",
            "5. Recruit fresh talent through university collaborations (no deadline specified).\n",
            "6. Innovate solutions through fresh perspectives (no deadline specified).\n",
            "7. Set aside a budget for internal R&D (no deadline specified).\n",
            "\n",
            "SOURCES:\n",
            "\n",
            "* synthetic_transcript.vtt (lines 10-13, 18-24)\n",
            "* synthetic_transcript.vtt (lines 20-24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Decisions Made\n",
        "response = summarize_and_qa.qa(\"List the decisions made in the meeting\",chain_type=\"map_reduce\")\n",
        "print(response[\"output_text\"])"
      ],
      "metadata": {
        "id": "U0nYjjL94mx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c5a9e4-a385-4a5d-9f5c-cb88c654682d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2094 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The decisions made in the meeting are:\n",
            "\n",
            "1. Create a dedicated AI support team.\n",
            "2. Showcase case studies and real-world applications of AI solutions.\n",
            "3. Coordinate with the sales team and arrange a workshop for clients.\n",
            "4. Gather feedback from clients to understand their specific needs in AI solutions.\n",
            "5. Implement a regular training schedule for the team to stay up-to-date with the latest AI advancements.\n",
            "6. Evaluate the company's infrastructure needs for scalable AI.\n",
            "7. Scout for potential partnerships in the tech space.\n",
            "8. Establish a dedicated ethics committee for AI.\n",
            "9. Ensure ethical soundness of products through regular reviews.\n",
            "10. Use \"Ethically Designed AI Solutions\" as a selling point.\n",
            "\n",
            "SOURCES:\n",
            "\n",
            "1. synthetic_transcript.vtt\n",
            "2. synthetic_transcript.vtt\n",
            "3. synthetic_transcript.vtt\n",
            "4. synthetic_transcript.vtt\n",
            "5. synthetic_transcript.vtt\n",
            "6. synthetic_transcript.vtt\n",
            "7. synthetic_transcript.vtt\n",
            "8. synthetic_transcript.vtt\n",
            "9. synthetic_transcript.vtt\n",
            "10. synthetic_transcript.vtt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Questions raised\n",
        "response = summarize_and_qa.qa(\"list all the questions raised in the meeting, and answers provided.\",chain_type=\"map_reduce\")\n",
        "print(response[\"output_text\"])"
      ],
      "metadata": {
        "id": "XS0tnZhf8p4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3606b6-5f35-4781-b3d7-6876e60fc22d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2019 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Questions raised in the meeting:\n",
            "\n",
            "1. How to pique interest and drive sales of AI solutions?\n",
            "2. How to understand what clients are specifically looking for in AI solutions?\n",
            "3. How to ensure the team is up-to-date with the latest AI advancements?\n",
            "4. Proposal for the team structure and responsibilities of the dedicated AI support team.\n",
            "5. What are the infrastructure needs for scalable AI?\n",
            "6. Who will lead the team to evaluate infrastructure needs?\n",
            "7. How long will the evaluation take?\n",
            "8. What is the concern regarding AI development?\n",
            "9. What is the suggestion to address security concerns?\n",
            "10. How do we plan to support these AI solutions?\n",
            "11. How can we ensure our products are ethically sound?\n",
            "12. What are the ethical implications of generative AI?\n",
            "\n",
            "Answers provided:\n",
            "\n",
            "1. By demonstrating AI capabilities firsthand through a workshop for clients, showcasing case studies and real-world applications, emphasizing customization and client-specific benefits.\n",
            "2. By gathering feedback from clients.\n",
            "3. By implementing a regular training schedule.\n",
            "4. AJ Principal Architect: I'll draft a proposal for the team structure and responsibilities. We'll need a mix of technical and domain experts.\n",
            "5. Dedicated GPU clusters and collaborations with cloud providers might be necessary.\n",
            "6. AJ Principal Architect will collaborate with AC Head of Architecture.\n",
            "7. About three weeks.\n",
            "8. Security is a concern, and client trust is paramount.\n",
            "9. Set up a dedicated team to ensure AI solutions comply with all relevant data protection regulations.\n",
            "10. Post-deployment support will be crucial for client trust.\n",
            "11. A dedicated ethics committee for AI might be a good idea. We can have regular reviews and ensure our products are ethically sound.\n",
            "12. Generative AI can be misused. Our products should have safeguards against misuse.\n"
          ]
        }
      ]
    }
  ]
}